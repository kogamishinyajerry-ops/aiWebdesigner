#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èŒä¸šç¢°ç“·å¼ç»´æƒæ¡ˆä»¶ - è¨€è¯­ä¸¾åŠ¨åˆ†æå·¥å…·

ç”¨äºåˆ†æç›‘æ§å½•åƒä¸­çš„å…³é”®è¨€è¯­å’Œä¸¾åŠ¨ï¼Œç”Ÿæˆæ—¶é—´æˆ³åˆ†æè¡¨
"""

from datetime import datetime, timedelta
from typing import List, Dict, Any
import json


class SpeechBehaviorAnalyzer:
    """è¨€è¯­ä¸¾åŠ¨åˆ†æå™¨"""
    
    def __init__(self):
        self.speeches = []
        self.behaviors = []
        self.timeline = []
    
    def add_speech(self, time_str: str, speaker: str, content: str,
                   category: str, analysis: str, importance: int):
        """æ·»åŠ è¨€è¯­è®°å½•
        
        Args:
            time_str: æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚ "00:05:30"ï¼‰
            speaker: è¯´è¯äººï¼ˆå¯¹æ–¹/æˆ‘æ–¹/åŒæ–¹ï¼‰
            content: è¨€è¯­å†…å®¹
            category: ç±»åˆ«ï¼ˆæŒ‘è¡…æ€§/å–è¯æ€§/å¨èƒæ€§/æ­£å¸¸ï¼‰
            analysis: ä¸“ä¸šåˆ†æ
            importance: é‡è¦æ€§ï¼ˆ1-5ï¼Œ5ä¸ºæœ€é«˜ï¼‰
        """
        self.speeches.append({
            "æ—¶é—´": time_str,
            "è¯´è¯äºº": speaker,
            "å†…å®¹": content,
            "ç±»åˆ«": category,
            "ä¸“ä¸šåˆ†æ": analysis,
            "é‡è¦æ€§": importance,
            "æ—¶é—´æˆ³": self._parse_time(time_str)
        })
    
    def add_behavior(self, time_str: str, actor: str, action: str,
                     category: str, analysis: str, importance: int):
        """æ·»åŠ è¡Œä¸ºè®°å½•
        
        Args:
            time_str: æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚ "00:05:30"ï¼‰
            actor: è¡Œä¸ºäººï¼ˆå¯¹æ–¹/æˆ‘æ–¹/åŒæ–¹ï¼‰
            action: è¡Œä¸ºæè¿°
            category: ç±»åˆ«ï¼ˆå¼‚å¸¸å†·é™/åˆ¶é€ åœºæ™¯/æ—¶é—´ç²¾ç¡®/æ­£å¸¸ï¼‰
            analysis: ä¸“ä¸šåˆ†æ
            importance: é‡è¦æ€§ï¼ˆ1-5ï¼Œ5ä¸ºæœ€é«˜ï¼‰
        """
        self.behaviors.append({
            "æ—¶é—´": time_str,
            "è¡Œä¸ºäºº": actor,
            "è¡Œä¸º": action,
            "ç±»åˆ«": category,
            "ä¸“ä¸šåˆ†æ": analysis,
            "é‡è¦æ€§": importance,
            "æ—¶é—´æˆ³": self._parse_time(time_str)
        })
    
    def _parse_time(self, time_str: str) -> int:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’æ•°"""
        try:
            parts = time_str.split(':')
            if len(parts) == 3:
                h, m, s = map(int, parts)
                return h * 3600 + m * 60 + s
            elif len(parts) == 2:
                m, s = map(int, parts)
                return m * 60 + s
            else:
                return 0
        except:
            return 0
    
    def generate_timeline(self):
        """ç”Ÿæˆå®Œæ•´æ—¶é—´çº¿"""
        self.timeline = []
        
        # åˆå¹¶è¨€è¯­å’Œè¡Œä¸º
        for speech in self.speeches:
            self.timeline.append({
                "ç±»å‹": "è¨€è¯­",
                **speech
            })
        
        for behavior in self.behaviors:
            self.timeline.append({
                "ç±»å‹": "è¡Œä¸º",
                **behavior
            })
        
        # æŒ‰æ—¶é—´æ’åº
        self.timeline.sort(key=lambda x: x["æ—¶é—´æˆ³"])
    
    def filter_by_category(self, category: str, item_type: str = None):
        """æŒ‰ç±»åˆ«ç­›é€‰
        
        Args:
            category: ç±»åˆ«ï¼ˆå¦‚ "æŒ‘è¡…æ€§"ã€"å–è¯æ€§"ã€"å¨èƒæ€§"ï¼‰
            item_type: é¡¹ç›®ç±»å‹ï¼ˆ"è¨€è¯­"/"è¡Œä¸º"/Noneè¡¨ç¤ºå…¨éƒ¨ï¼‰
        """
        results = []
        
        if item_type is None or item_type == "è¨€è¯­":
            for speech in self.speeches:
                if category in speech["ç±»åˆ«"]:
                    results.append(speech)
        
        if item_type is None or item_type == "è¡Œä¸º":
            for behavior in self.behaviors:
                if category in behavior["ç±»åˆ«"]:
                    results.append(behavior)
        
        return sorted(results, key=lambda x: x["æ—¶é—´æˆ³"])
    
    def get_high_importance_items(self, threshold: int = 4):
        """è·å–é«˜é‡è¦æ€§é¡¹ç›®"""
        results = []
        
        for speech in self.speeches:
            if speech["é‡è¦æ€§"] >= threshold:
                results.append(speech)
        
        for behavior in self.behaviors:
            if behavior["é‡è¦æ€§"] >= threshold:
                results.append(behavior)
        
        return sorted(results, key=lambda x: x["æ—¶é—´æˆ³"])
    
    def generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
        summary = {
            "è¨€è¯­æ€»æ•°": len(self.speeches),
            "è¡Œä¸ºæ€»æ•°": len(self.behaviors),
            "è¨€è¯­ç±»åˆ«ç»Ÿè®¡": {},
            "è¡Œä¸ºç±»åˆ«ç»Ÿè®¡": {},
            "é«˜é‡è¦æ€§é¡¹ç›®æ•°": len(self.get_high_importance_items(4)),
            "å¯¹æ–¹è¯´è¯æ¬¡æ•°": len([s for s in self.speeches if s["è¯´è¯äºº"] == "å¯¹æ–¹"]),
            "æˆ‘æ–¹è¯´è¯æ¬¡æ•°": len([s for s in self.speeches if s["è¯´è¯äºº"] == "æˆ‘æ–¹"])
        }
        
        # ç»Ÿè®¡è¨€è¯­ç±»åˆ«
        for speech in self.speeches:
            category = speech["ç±»åˆ«"]
            summary["è¨€è¯­ç±»åˆ«ç»Ÿè®¡"][category] = summary["è¨€è¯­ç±»åˆ«ç»Ÿè®¡"].get(category, 0) + 1
        
        # ç»Ÿè®¡è¡Œä¸ºç±»åˆ«
        for behavior in self.behaviors:
            category = behavior["ç±»åˆ«"]
            summary["è¡Œä¸ºç±»åˆ«ç»Ÿè®¡"][category] = summary["è¡Œä¸ºç±»åˆ«ç»Ÿè®¡"].get(category, 0) + 1
        
        return summary
    
    def generate_markdown(self) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        md = []
        
        # æ ‡é¢˜
        md.append("# è¨€è¯­ä¸¾åŠ¨åˆ†ææŠ¥å‘Š\n")
        md.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # ç»Ÿè®¡æ‘˜è¦
        summary = self.generate_summary()
        md.append("## ğŸ“Š ç»Ÿè®¡æ‘˜è¦\n")
        md.append(f"- **è¨€è¯­æ€»æ•°**: {summary['è¨€è¯­æ€»æ•°']}")
        md.append(f"- **è¡Œä¸ºæ€»æ•°**: {summary['è¡Œä¸ºæ€»æ•°']}")
        md.append(f"- **é«˜é‡è¦æ€§é¡¹ç›®**: {summary['é«˜é‡è¦æ€§é¡¹ç›®æ•°']}")
        md.append(f"- **å¯¹æ–¹è¯´è¯æ¬¡æ•°**: {summary['å¯¹æ–¹è¯´è¯æ¬¡æ•°']}")
        md.append(f"- **æˆ‘æ–¹è¯´è¯æ¬¡æ•°**: {summary['æˆ‘æ–¹è¯´è¯æ¬¡æ•°']}\n")
        
        # è¨€è¯­ç±»åˆ«ç»Ÿè®¡
        md.append("### è¨€è¯­ç±»åˆ«ç»Ÿè®¡")
        for category, count in summary["è¨€è¯­ç±»åˆ«ç»Ÿè®¡"].items():
            md.append(f"- **{category}**: {count} æ¬¡")
        md.append("")
        
        # è¡Œä¸ºç±»åˆ«ç»Ÿè®¡
        md.append("### è¡Œä¸ºç±»åˆ«ç»Ÿè®¡")
        for category, count in summary["è¡Œä¸ºç±»åˆ«ç»Ÿè®¡"].items():
            md.append(f"- **{category}**: {count} æ¬¡")
        md.append("")
        
        # é«˜é‡è¦æ€§é¡¹ç›®
        md.append("## â­ é«˜é‡è¦æ€§é¡¹ç›®ï¼ˆé‡è¦æ€§ â‰¥ 4ï¼‰\n")
        high_importance = self.get_high_importance_items(4)
        for i, item in enumerate(high_importance, 1):
            icon = "ğŸ’¬" if "å†…å®¹" in item else "ğŸ¬"
            stars = "â­" * item["é‡è¦æ€§"]
            md.append(f"{icon} **{i}. [{item['æ—¶é—´']}] {item.get('å†…å®¹', item.get('è¡Œä¸º', ''))}** {stars}")
            md.append(f"   - ç±»å‹: {item['ç±»åˆ«']}")
            md.append(f"   - ä¸“ä¸šåˆ†æ: {item['ä¸“ä¸šåˆ†æ']}")
            md.append("")
        
        # æŒ‰ç±»åˆ«åˆ†ç±»
        md.append("## ğŸ“‹ æŒ‰ç±»åˆ«åˆ†ç±»\n")
        
        # æŒ‘è¡…æ€§è¨€è¯­
        provocative_speeches = self.filter_by_category("æŒ‘è¡…æ€§", "è¨€è¯­")
        if provocative_speeches:
            md.append("### ğŸ’¥ æŒ‘è¡…æ€§è¨€è¯­\n")
            for speech in provocative_speeches:
                stars = "â­" * speech["é‡è¦æ€§"]
                md.append(f"**[{speech['æ—¶é—´']}] {speech['è¯´è¯äºº']}**: \"{speech['å†…å®¹']}\" {stars}")
                md.append(f"> {speech['ä¸“ä¸šåˆ†æ']}\n")
        
        # å–è¯æ€§è¨€è¯­
        evidentiary_speeches = self.filter_by_category("å–è¯æ€§", "è¨€è¯­")
        if evidentiary_speeches:
            md.append("### ğŸ“¸ å–è¯æ€§è¨€è¯­\n")
            for speech in evidentiary_speeches:
                stars = "â­" * speech["é‡è¦æ€§"]
                md.append(f"**[{speech['æ—¶é—´']}] {speech['è¯´è¯äºº']}**: \"{speech['å†…å®¹']}\" {stars}")
                md.append(f"> {speech['ä¸“ä¸šåˆ†æ']}\n")
        
        # å¨èƒæ€§è¨€è¯­
        threatening_speeches = self.filter_by_category("å¨èƒæ€§", "è¨€è¯­")
        if threatening_speeches:
            md.append("### âš ï¸ å¨èƒæ€§è¨€è¯­\n")
            for speech in threatening_speeches:
                stars = "â­" * speech["é‡è¦æ€§"]
                md.append(f"**[{speech['æ—¶é—´']}] {speech['è¯´è¯äºº']}**: \"{speech['å†…å®¹']}\" {stars}")
                md.append(f"> {speech['ä¸“ä¸šåˆ†æ']}\n")
        
        # å¼‚å¸¸å†·é™è¡Œä¸º
        calm_behaviors = self.filter_by_category("å¼‚å¸¸å†·é™", "è¡Œä¸º")
        if calm_behaviors:
            md.append("### ğŸ˜¶ å¼‚å¸¸å†·é™è¡Œä¸º\n")
            for behavior in calm_behaviors:
                stars = "â­" * behavior["é‡è¦æ€§"]
                md.append(f"**[{behavior['æ—¶é—´']}] {behavior['è¡Œä¸ºäºº']}**: {behavior['è¡Œä¸º']} {stars}")
                md.append(f"> {behavior['ä¸“ä¸šåˆ†æ']}\n")
        
        # åˆ¶é€ åœºæ™¯è¡Œä¸º
        scene_behaviors = self.filter_by_category("åˆ¶é€ åœºæ™¯", "è¡Œä¸º")
        if scene_behaviors:
            md.append("### ğŸ­ åˆ¶é€ åœºæ™¯è¡Œä¸º\n")
            for behavior in scene_behaviors:
                stars = "â­" * behavior["é‡è¦æ€§"]
                md.append(f"**[{behavior['æ—¶é—´']}] {behavior['è¡Œä¸ºäºº']}**: {behavior['è¡Œä¸º']} {stars}")
                md.append(f"> {behavior['ä¸“ä¸šåˆ†æ']}\n")
        
        # æ—¶é—´ç²¾ç¡®è¡Œä¸º
        time_behaviors = self.filter_by_category("æ—¶é—´ç²¾ç¡®", "è¡Œä¸º")
        if time_behaviors:
            md.append("### â° æ—¶é—´ç²¾ç¡®è¡Œä¸º\n")
            for behavior in time_behaviors:
                stars = "â­" * behavior["é‡è¦æ€§"]
                md.append(f"**[{behavior['æ—¶é—´']}] {behavior['è¡Œä¸ºäºº']}**: {behavior['è¡Œä¸º']} {stars}")
                md.append(f"> {behavior['ä¸“ä¸šåˆ†æ']}\n")
        
        # å®Œæ•´æ—¶é—´çº¿
        md.append("## ğŸ“… å®Œæ•´æ—¶é—´çº¿\n")
        self.generate_timeline()
        for i, item in enumerate(self.timeline, 1):
            icon = "ğŸ’¬" if item["ç±»å‹"] == "è¨€è¯­" else "ğŸ¬"
            content = item.get("å†…å®¹", item.get("è¡Œä¸º", ""))
            speaker = item.get("è¯´è¯äºº", item.get("è¡Œä¸ºäºº", ""))
            md.append(f"{icon} **{i}. [{item['æ—¶é—´']}] {speaker}**: {content}")
            md.append(f"   - ç±»åˆ«: {item['ç±»åˆ«']}")
            md.append(f"   - é‡è¦æ€§: {'â­' * item['é‡è¦æ€§']}")
            md.append("")
        
        return "\n".join(md)
    
    def generate_json(self) -> str:
        """ç”Ÿæˆ JSON æ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        data = {
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "ç»Ÿè®¡æ‘˜è¦": self.generate_summary(),
            "è¨€è¯­è®°å½•": self.speeches,
            "è¡Œä¸ºè®°å½•": self.behaviors,
            "å®Œæ•´æ—¶é—´çº¿": self.timeline
        }
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    def save_to_file(self, filename: str, format: str = "markdown"):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        if format == "markdown":
            content = self.generate_markdown()
            ext = ".md"
        elif format == "json":
            content = self.generate_json()
            ext = ".json"
        else:
            raise ValueError("æ ¼å¼å¿…é¡»æ˜¯ 'markdown' æˆ– 'json'")
        
        full_filename = filename + ext
        with open(full_filename, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return full_filename


def create_sample_analysis():
    """åˆ›å»ºç¤ºä¾‹åˆ†æ"""
    analyzer = SpeechBehaviorAnalyzer()
    
    # æ·»åŠ è¨€è¯­è®°å½•ï¼ˆæ¨¡æ‹ŸèŒä¸šç¢°ç“·æ¡ˆä¾‹ï¼‰
    speeches = [
        # ç¼ æ–—æœŸï¼ˆ0-60åˆ†é’Ÿï¼‰
        ("00:05:00", "å¯¹æ–¹", "ä½ ä»¬åº—å°±è¿™æ ·åšç”Ÿæ„çš„ï¼Ÿ", "æŒ‘è¡…æ€§", "æš—ç¤ºå•†æˆ·æœåŠ¡è´¨é‡å·®", 3),
        ("00:10:00", "å¯¹æ–¹", "æˆ‘çœ‹ä½ ä»¬å°±æ˜¯æ¬ºè´Ÿå¤–åœ°äºº", "æŒ‘è¡…æ€§", "æ ‡ç­¾åŒ–æ”»å‡»ï¼Œåˆ¶é€ çŸ›ç›¾", 4),
        ("00:20:00", "å¯¹æ–¹", "æˆ‘éƒ½ç­‰ä½ è¿™ä¹ˆä¹…äº†", "æŒ‘è¡…æ€§", "å¼ºè°ƒ'å—å®³è€…'èº«ä»½", 2),
        ("00:45:00", "å¯¹æ–¹", "èƒ½ä¸èƒ½ä¾¿å®œç‚¹ï¼Ÿ", "æ­£å¸¸", "æ­£å¸¸è®®ä»·", 1),
        ("01:00:00", "å¯¹æ–¹", "è¡Œå§ï¼Œå°±å½“æˆ‘å€’éœ‰", "æŒ‘è¡…æ€§", "æš—ç¤ºè¢«è¿«äº¤æ˜“", 3),
        
        # çˆ†ç ´æœŸï¼ˆäº¤æ˜“åå³åˆ»ï¼‰
        ("01:05:00", "å¯¹æ–¹", "ä½ ä»¬ä¸ç»™èµ å“å°±é€€æ¬¾", "æŒ‘è¡…æ€§", "åˆ¶é€ äº¤æ˜“éšœç¢", 4),
        ("01:06:00", "å¯¹æ–¹", "æˆ‘çœ‹ä½ ä»¬å°±æ˜¯ä¸æƒ³å–", "æŒ‘è¡…æ€§", "æŒ‡è´£å•†æˆ·è¿çº¦", 4),
        
        # å†²çªæœŸï¼ˆå•†æˆ·çˆ†å‘æ—¶ï¼‰
        ("01:10:00", "å¯¹æ–¹", "ä½ åˆšæ‰è¯´ä»€ä¹ˆï¼Ÿå†è¯´ä¸€éï¼", "å–è¯æ€§", "å¼•å¯¼å•†æˆ·é‡å¤æ¿€çƒˆè¨€è¯­", 5),
        ("01:10:30", "å¯¹æ–¹", "ä½ æ•¢ä¸æ•¢å†è¯´ä¸€éï¼Ÿ", "å–è¯æ€§", "è¿›ä¸€æ­¥å¼•å¯¼ï¼Œè·å–æ›´æ¿€çƒˆè¨€è¯­", 5),
        ("01:11:00", "å¯¹æ–¹", "å¤§å®¶çœ‹çœ‹ï¼Œè¿™å°±æ˜¯è¿™å®¶åº—çš„æ€åº¦", "å–è¯æ€§", "åˆ¶é€ èˆ†è®ºåœºæ™¯", 4),
        ("01:12:00", "å¯¹æ–¹", "æˆ‘è¦æŠ¥è­¦äº†ï¼Œä½ ä»¬ç­‰ç€", "å¨èƒæ€§", "å¨èƒï¼Œä¸ºåç»­æŠ•è¯‰åšé“ºå«", 3),
        ("01:13:00", "å¯¹æ–¹", "ï¼ˆå¯¹ç€æ‰‹æœºå½•åƒè¯´ï¼‰è¿™å®¶åº—åœ¨å¨èƒæˆ‘", "å–è¯æ€§", "å–è¯è¯æœ¯", 5),
        ("01:15:00", "å¯¹æ–¹", "æˆ‘è¦è®©ä½ ä»¬è¿™åº—å¼€ä¸ä¸‹å»", "å¨èƒæ€§", "ç›´æ¥å¨èƒ", 5),
        ("01:16:00", "å¯¹æ–¹", "æˆ‘ä¼šè®©å¤§å®¶éƒ½çŸ¥é“ä½ ä»¬åº—çš„æ ·å­", "å¨èƒæ€§", "å¨èƒæ›å…‰", 4),
        ("01:17:00", "å¯¹æ–¹", "æˆ‘è¦å»æŠ•è¯‰ä½ ä»¬", "å¨èƒæ€§", "è¡Œæ”¿å¨èƒ", 3),
        ("01:18:00", "å¯¹æ–¹", "æˆ‘è¦å‘åˆ°ç½‘ä¸Šå»", "å¨èƒæ€§", "èˆ†è®ºå¨èƒ", 4),
        ("01:19:00", "å¯¹æ–¹", "ä½ ä»¬ç­‰ç€ï¼Œä¸ä¼šå°±è¿™ä¹ˆç®—äº†", "å¨èƒæ€§", "ç»§ç»­å¨èƒ", 4)
    ]
    
    for time_str, speaker, content, category, analysis, importance in speeches:
        analyzer.add_speech(time_str, speaker, content, category, analysis, importance)
    
    # æ·»åŠ è¡Œä¸ºè®°å½•
    behaviors = [
        # ç¼ æ–—æœŸï¼ˆ0-60åˆ†é’Ÿï¼‰
        ("00:03:00", "å¯¹æ–¹", "ç«™åœ¨åº—é“ºé—¨å£ä¸åŠ¨", "åˆ¶é€ åœºæ™¯", "åˆ¶é€ 'åº—å¤§æ¬ºå®¢'è§†è§‰å‡è±¡", 4),
        ("00:05:00", "å¯¹æ–¹", "æ‹¿å‡ºæ‰‹æœºå¼€å§‹å½•åƒ", "å¼‚å¸¸å†·é™", "èŒä¸šå–è¯ä¹ æƒ¯", 4),
        ("00:10:00", "å¯¹æ–¹", "é¢‘ç¹æ‹ç…§", "å¼‚å¸¸å†·é™", "å…¨ç¨‹å–è¯", 4),
        ("00:15:00", "å¯¹æ–¹", "é˜»ç¢å…¶ä»–é¡¾å®¢è¿›å…¥åº—é“º", "åˆ¶é€ åœºæ™¯", "æ‰©å¤§å†²çªå½±å“èŒƒå›´", 5),
        ("00:30:00", "å¯¹æ–¹", "åå¤è¯•ç”¨å•†å“", "æ­£å¸¸", "æ­£å¸¸æ¶ˆè´¹è¡Œä¸º", 1),
        
        # å†²çªæœŸ
        ("01:08:00", "å¯¹æ–¹", "åŸåœ°æ‹ç…§", "å¼‚å¸¸å†·é™", "æ­£å¸¸ååº”æ˜¯é€ƒè·‘æˆ–æƒŠæ…Œï¼Œè€Œä¸æ˜¯å–è¯", 5),
        ("01:09:00", "å¯¹æ–¹", "å†·é™æˆªå›¾", "å¼‚å¸¸å†·é™", "æåº¦ç¬¦åˆå—è¿‡è®­ç»ƒçš„ç‰¹å¾", 5),
        ("01:11:00", "å¯¹æ–¹", "å¤§å£°è¯´è¯å¸å¼•æ³¨æ„", "åˆ¶é€ åœºæ™¯", "åˆ¶é€ å›´è§‚è€…", 4),
        ("01:12:00", "å¯¹æ–¹", "ç°åœºæŠ¥è­¦", "å¼‚å¸¸å†·é™", "ä¸æ˜¯åœ¨æ±‚åŠ©ï¼Œè€Œæ˜¯åœ¨æ‰§è¡Œé¢„æ¡ˆ", 5),
        ("01:13:00", "å¯¹æ–¹", "å¯¹ç€æ‰‹æœºå“­è¯‰", "åˆ¶é€ åœºæ™¯", "å¼ºåŒ–'å¥³æ€§å¼±åŠ¿å—å®³è€…'äººè®¾", 4),
        ("01:14:00", "å¯¹æ–¹", "ä¸é€ƒè·‘", "å¼‚å¸¸å†·é™", "ç­‰å¾…å•†æˆ·'å‡¶ç‹ 'ç”»é¢", 4),
        ("01:15:00", "å¯¹æ–¹", "å¯¹ç€æ‰‹æœºè¯´'æˆ‘å¥½å®³æ€•'", "åˆ¶é€ åœºæ™¯", "è¡¨æ¼”æŠ€è‰º", 4),
        
        # æ¬¡æ—¥æ¸…æ™¨
        ("06:47:00", "å¯¹æ–¹", "å‘å¸ƒå°çº¢ä¹¦åšæ–‡", "æ—¶é—´ç²¾ç¡®", "ç¤¾äº¤åª’ä½“ç®—æ³•æ¨èçš„'é»„é‡‘æ—©é«˜å³°'", 5)
    ]
    
    for time_str, actor, action, category, analysis, importance in behaviors:
        analyzer.add_behavior(time_str, actor, action, category, analysis, importance)
    
    return analyzer


if __name__ == "__main__":
    # åˆ›å»ºç¤ºä¾‹åˆ†æ
    print("æ­£åœ¨ç”Ÿæˆè¨€è¯­ä¸¾åŠ¨åˆ†æ...")
    analyzer = create_sample_analysis()
    
    # ä¿å­˜ä¸º Markdown æ ¼å¼
    md_file = analyzer.save_to_file("/workspace/ai_detective/speech_behavior_analysis", "markdown")
    print(f"âœ… Markdown æ ¼å¼å·²ä¿å­˜: {md_file}")
    
    # ä¿å­˜ä¸º JSON æ ¼å¼
    json_file = analyzer.save_to_file("/workspace/ai_detective/speech_behavior_analysis", "json")
    print(f"âœ… JSON æ ¼å¼å·²ä¿å­˜: {json_file}")
    
    # æ˜¾ç¤ºæ‘˜è¦
    summary = analyzer.generate_summary()
    print("\n" + "="*60)
    print("è¨€è¯­ä¸¾åŠ¨åˆ†æç”Ÿæˆå®Œæˆï¼")
    print("="*60)
    print(f"è¨€è¯­æ€»æ•°: {summary['è¨€è¯­æ€»æ•°']}")
    print(f"è¡Œä¸ºæ€»æ•°: {summary['è¡Œä¸ºæ€»æ•°']}")
    print(f"é«˜é‡è¦æ€§é¡¹ç›®: {summary['é«˜é‡è¦æ€§é¡¹ç›®æ•°']}")
    print(f"å¯¹æ–¹è¯´è¯æ¬¡æ•°: {summary['å¯¹æ–¹è¯´è¯æ¬¡æ•°']}")
    print(f"æˆ‘æ–¹è¯´è¯æ¬¡æ•°: {summary['æˆ‘æ–¹è¯´è¯æ¬¡æ•°']}")
    print(f"\nè¨€è¯­ç±»åˆ«ç»Ÿè®¡:")
    for category, count in summary["è¨€è¯­ç±»åˆ«ç»Ÿè®¡"].items():
        print(f"  - {category}: {count} æ¬¡")
    print(f"\nè¡Œä¸ºç±»åˆ«ç»Ÿè®¡:")
    for category, count in summary["è¡Œä¸ºç±»åˆ«ç»Ÿè®¡"].items():
        print(f"  - {category}: {count} æ¬¡")
    print("="*60)
